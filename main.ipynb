{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dd679f8",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ec9d67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "import cv2\n",
    "\n",
    "\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b03135",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9212336d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset that does LAB conversion on-the-fly\n",
    "class CIFAR10ColorizationDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.dataset = CIFAR10(root='./data', download=True,\n",
    "                               transform=transforms.Compose([\n",
    "                                   transforms.ToTensor()\n",
    "                               ]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, _ = self.dataset[idx]  # img: [C, H, W] tensor\n",
    "\n",
    "        # Convert to numpy\n",
    "        img_np = img.permute(1,2,0).numpy()\n",
    "        img_np = (img_np * 255).astype('uint8')\n",
    "\n",
    "        # RGB to LAB\n",
    "        lab = cv2.cvtColor(img_np, cv2.COLOR_RGB2LAB)\n",
    "        l_channel = lab[:,:,0] / 255.0\n",
    "        ab_channels = (lab[:,:,1:] - 128) / 128.0\n",
    "\n",
    "        # Tensors\n",
    "        l = torch.tensor(l_channel).unsqueeze(0).float()\n",
    "        ab = torch.tensor(ab_channels).permute(2,0,1).float()\n",
    "\n",
    "        return l, ab\n",
    "\n",
    "# Create Dataset\n",
    "colorization_dataset = CIFAR10ColorizationDataset()\n",
    "\n",
    "# Create DataLoader\n",
    "dataloader = DataLoader(colorization_dataset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7c09f9",
   "metadata": {},
   "source": [
    "## Verify dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbbd3546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get one batch\n",
    "l_batch, ab_batch = next(iter(dataloader))  # l_batch: [batch, 1, 128, 128], ab_batch: [batch, 2, 128, 128]\n",
    "\n",
    "# Pick the first sample from batch\n",
    "l = l_batch[0]    # [1, 128, 128]\n",
    "ab = ab_batch[0]  # [2, 128, 128]\n",
    "\n",
    "# Recover LAB image\n",
    "l_img = (l.squeeze(0).numpy() * 255).astype('uint8')  # [128, 128], back to [0,255]\n",
    "ab_img = (ab.permute(1,2,0).numpy() * 128) + 128      # [128, 128, 2], back to OpenCV LAB space\n",
    "\n",
    "# Stack into LAB image\n",
    "lab = np.zeros((32, 32, 3), dtype=np.uint8)\n",
    "lab[:,:,0] = l_img\n",
    "lab[:,:,1:] = ab_img.astype('uint8')\n",
    "\n",
    "# Convert LAB -> RGB for viewing\n",
    "rgb = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "axes[0].imshow(l_img, cmap='gray')\n",
    "axes[0].set_title('L-channel (grayscale input)')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(rgb)\n",
    "axes[1].set_title('Reconstructed color image')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d1d57e",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f2f87e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, scheduler, num_epochs=10):\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        loop = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=True)\n",
    "\n",
    "        for l_batch, ab_batch in loop:\n",
    "            l_batch = l_batch.to(device)\n",
    "            ab_batch = ab_batch.to(device)\n",
    "\n",
    "            output = model(l_batch)\n",
    "            loss = criterion(output, ab_batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_loss = running_loss / len(dataloader)\n",
    "        losses.append(avg_loss)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # 🔵 Save the model every 20 epochs\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            checkpoint_filename = f\"model_epoch_smoothl1_{epoch+1}.pth\"\n",
    "            torch.save(model.state_dict(), checkpoint_filename)\n",
    "            print(f\"✅ Saved checkpoint at {checkpoint_filename}\")\n",
    "\n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ec0d6f",
   "metadata": {},
   "source": [
    "# Encoder-Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a004c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepColorizationCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepColorizationCNN, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1), \n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=0),  # 1 -> 64 kernels\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ReflectionPad2d(1), \n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2), \n",
    "            nn.MaxPool2d(2, 2),  # downsample\n",
    "            nn.Dropout2d(0.2),\n",
    "\n",
    "            nn.ReflectionPad2d(1), \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=0),  # 64 -> 128\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ReflectionPad2d(1), \n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=0),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.MaxPool2d(2, 2),  # downsample\n",
    "            nn.Dropout2d(0.2),\n",
    "\n",
    "            nn.ReflectionPad2d(2), \n",
    "            nn.Conv2d(128, 256, kernel_size=5, padding=0),  # 128 -> 256\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ReflectionPad2d(2), \n",
    "            nn.Conv2d(256, 256, kernel_size=5, padding=0),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.LeakyReLU(0.2), # Reduced to 8x8 image\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2),  # upsample\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ReflectionPad2d(1), \n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=0),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),  # upsample\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ReflectionPad2d(1), \n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.ReflectionPad2d(1), \n",
    "            nn.Conv2d(64, 2, kernel_size=3, padding=0),  # output 2 channels (ab)\n",
    "            nn.Tanh()  # normalized between [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b11eb6",
   "metadata": {},
   "source": [
    "## Train encoder-decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14c81c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepColorizationCNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "losses = train(model, optimizer, criterion)\n",
    "# Plot the training losses\n",
    "plt.plot(losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5a20da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save progress\n",
    "torch.save(model.state_dict(), \"colorizer.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccce255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from file\n",
    "model = DeepColorizationCNN().to(device)        # 1. recreate model\n",
    "model.load_state_dict(torch.load(\"colorizer.pth\"))  # 2. load weights\n",
    "model.eval()      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9b139b",
   "metadata": {},
   "source": [
    "## Encoder-Decoder Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9190ce77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recolor_image(model, filepath):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    # 1. Load and preprocess image\n",
    "    img = cv2.imread(filepath)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    l_channel = img[:, :, 0]  # [H, W]\n",
    "\n",
    "    orig_shape = l_channel.shape  # Save shape for later\n",
    "\n",
    "    # Normalize L\n",
    "    l = l_channel / 255.0\n",
    "    l = torch.tensor(l).unsqueeze(0).unsqueeze(0).float().to(device)  # [1, 1, H, W]\n",
    "\n",
    "    # 2. Feed through model\n",
    "    with torch.no_grad():\n",
    "        pred_ab = model(l)  # [1, 2, H, W]\n",
    "        pred_ab = pred_ab.squeeze(0).cpu()  # [2, H, W]\n",
    "\n",
    "    # 3. Postprocess\n",
    "    pred_ab = pred_ab.permute(1, 2, 0).numpy()  # [H, W, 2]\n",
    "    pred_ab = (pred_ab * 128) + 128  # Denormalize back to OpenCV format\n",
    "\n",
    "    # Denormalize L back to [0, 255]\n",
    "    l_channel = l_channel.astype(np.uint8)\n",
    "\n",
    "    # Stack L and ab back together\n",
    "    lab = np.zeros((orig_shape[0], orig_shape[1], 3), dtype=np.uint8)\n",
    "    lab[:, :, 0] = l_channel\n",
    "    lab[:, :, 1:] = pred_ab.astype(np.uint8)\n",
    "\n",
    "    # Convert LAB to BGR (for OpenCV display)\n",
    "    bgr = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    return bgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13f038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of image filenames (without needing to repeat code)\n",
    "image_names = [\"horse.jpg\", \"dog.jpg\", \"deer.jpg\", \"ship.jpg\"]\n",
    "\n",
    "# Prepare a list to hold (original, grayscale, recolored) for each image\n",
    "images = []\n",
    "\n",
    "for name in image_names:\n",
    "    img = cv2.imread(name)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    colorized = recolor_image(model, name)\n",
    "    \n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    colorized_rgb = cv2.cvtColor(colorized, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    images.append((img_rgb, gray, colorized_rgb))  # save tuple\n",
    "\n",
    "# Now plot\n",
    "fig, axes = plt.subplots(4, 3, figsize=(5, 4))  # (4 rows, 3 cols)\n",
    "\n",
    "for i in range(4):  # for each image\n",
    "    # Original\n",
    "    axes[i, 0].imshow(images[i][0])\n",
    "    axes[i, 0].set_title(f'Original {image_names[i][:-4].capitalize()}')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # Grayscale\n",
    "    axes[i, 1].imshow(images[i][1], cmap='gray')\n",
    "    axes[i, 1].set_title(f'Grayscale {image_names[i][:-4].capitalize()}')\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    # Recolored\n",
    "    axes[i, 2].imshow(images[i][2])\n",
    "    axes[i, 2].set_title(f'Recolored {image_names[i][:-4].capitalize()}')\n",
    "    axes[i, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02cf734",
   "metadata": {},
   "source": [
    "# U-Net Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "402ef505",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepColorizationUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepColorizationUNet, self).__init__()\n",
    "\n",
    "        # ------- Encoder ---------\n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(1, 64, 3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(64, 64, 3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.enc2 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(64, 128, 3),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(128, 128, 3),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.enc3 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(128, 256, 3),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(256, 256, 3),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.enc4 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(256, 512, 3),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(512, 512, 3),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        # ------- Bottleneck ---------\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(512, 1024, 3),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(1024, 1024, 3),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        # ------- Decoder ---------\n",
    "        self.upconv4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.dec4 = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(1024, 512, 3),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(512, 512, 3),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec3 = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(512, 256, 3),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(256, 256, 3),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec2 = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(256, 128, 3),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(128, 128, 3),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec1 = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(128, 64, 3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(64, 64, 3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        # Final 1x1 Conv to predict ab channels\n",
    "        self.final_conv = nn.Conv2d(64, 2, kernel_size=1)\n",
    "        self.final_activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(e1)\n",
    "        e3 = self.enc3(e2)\n",
    "        e4 = self.enc4(e3)\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(e4)\n",
    "\n",
    "        # Decoder with skips\n",
    "        d4 = self.upconv4(b)\n",
    "        d4 = torch.cat([d4, e4], dim=1)\n",
    "        d4 = self.dec4(d4)\n",
    "\n",
    "        d3 = self.upconv3(d4)\n",
    "        d3 = torch.cat([d3, e3], dim=1)\n",
    "        d3 = self.dec3(d3)\n",
    "\n",
    "        d2 = self.upconv2(d3)\n",
    "        d2 = torch.cat([d2, e2], dim=1)\n",
    "        d2 = self.dec2(d2)\n",
    "\n",
    "        d1 = self.upconv1(d2)\n",
    "        d1 = torch.cat([d1, e1], dim=1)\n",
    "        d1 = self.dec1(d1)\n",
    "\n",
    "        # Final output\n",
    "        out = self.final_conv(d1)\n",
    "        out = self.final_activation(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a280c36a",
   "metadata": {},
   "source": [
    "## Train UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f1c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model = DeepColorizationUNet().to(device) \n",
    "model.load_state_dict(torch.load(\"model_epoch_60.pth\"))\n",
    "model.train()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0204921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepColorizationUNet().to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47427130",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:   4%|▎         | 7/196 [00:04<02:09,  1.46it/s, loss=0.527]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      6\u001b[39m scheduler = OneCycleLR(\n\u001b[32m      7\u001b[39m     optimizer,\n\u001b[32m      8\u001b[39m     max_lr=\u001b[32m1e-3\u001b[39m,               \u001b[38;5;66;03m# Peak learning rate\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     anneal_strategy=\u001b[33m'\u001b[39m\u001b[33mcos\u001b[39m\u001b[33m'\u001b[39m       \u001b[38;5;66;03m# How to decay: 'cos' (cosine) or 'linear'\u001b[39;00m\n\u001b[32m     13\u001b[39m )\n\u001b[32m     14\u001b[39m criterion = nn.SmoothL1Loss()\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m losses = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m plt.plot(losses, label=\u001b[33m'\u001b[39m\u001b[33mTraining Loss\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     19\u001b[39m plt.xlabel(\u001b[33m'\u001b[39m\u001b[33mEpoch\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, optimizer, criterion, scheduler, num_epochs)\u001b[39m\n\u001b[32m     19\u001b[39m     optimizer.step()\n\u001b[32m     20\u001b[39m     scheduler.step()\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     running_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m     loop.set_postfix(loss=loss.item())\n\u001b[32m     26\u001b[39m avg_loss = running_loss / \u001b[38;5;28mlen\u001b[39m(dataloader)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "#model = DeepColorizationUNet().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=1e-3,               # Peak learning rate\n",
    "    steps_per_epoch=len(dataloader),\n",
    "    epochs=60,\n",
    "    pct_start=0.3,              # % of total steps to warmup (30% up, 70% down)\n",
    "    anneal_strategy='cos'       # How to decay: 'cos' (cosine) or 'linear'\n",
    ")\n",
    "criterion = nn.SmoothL1Loss()\n",
    "\n",
    "losses = train(model, optimizer, criterion, scheduler, num_epochs=60)\n",
    "\n",
    "plt.plot(losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a972936d",
   "metadata": {},
   "source": [
    "## Test U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5c97c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of image filenames (without needing to repeat code)\n",
    "image_names = [\"horse.jpg\", \"dog.jpg\", \"apple.jpg\", \"ship.jpg\"]\n",
    "\n",
    "# Prepare a list to hold (original, grayscale, recolored) for each image\n",
    "images = []\n",
    "\n",
    "for name in image_names:\n",
    "    img = cv2.imread(name)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    colorized = recolor_image(model, name)\n",
    "    \n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    colorized_rgb = cv2.cvtColor(colorized, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    images.append((img_rgb, gray, colorized_rgb))  # save tuple\n",
    "\n",
    "# Now plot\n",
    "fig, axes = plt.subplots(4, 3, figsize=(5, 4))  # (4 rows, 3 cols)\n",
    "\n",
    "for i in range(4):  # for each image\n",
    "    # Original\n",
    "    axes[i, 0].imshow(images[i][0])\n",
    "    axes[i, 0].set_title(f'Original {image_names[i][:-4].capitalize()}')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # Grayscale\n",
    "    axes[i, 1].imshow(images[i][1], cmap='gray')\n",
    "    axes[i, 1].set_title(f'Grayscale {image_names[i][:-4].capitalize()}')\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    # Recolored\n",
    "    axes[i, 2].imshow(images[i][2])\n",
    "    axes[i, 2].set_title(f'Recolored {image_names[i][:-4].capitalize()}')\n",
    "    axes[i, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95f0f27",
   "metadata": {},
   "source": [
    "### Save random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbc4f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "import os\n",
    "\n",
    "# 1. Define a simple transform (load as tensor)\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# 2. Load CIFAR-10 training set\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# 3. Pick a random index\n",
    "idx = random.randint(0, len(dataset) - 1)\n",
    "\n",
    "# 4. Get the image and label\n",
    "img_tensor, label = dataset[idx]\n",
    "\n",
    "# 5. Save the image\n",
    "\n",
    "# Make a folder if it doesn't exist\n",
    "os.makedirs('saved_images', exist_ok=True)\n",
    "\n",
    "# Turn tensor back to a grid (remove batch dimension)\n",
    "# vutils.save_image expects a mini-batch, so we unsqueeze to [1, C, H, W]\n",
    "vutils.save_image(img_tensor, f'saved_images/random_cifar10.jpg')\n",
    "\n",
    "print(f\"Saved random CIFAR-10 image with label: {dataset.classes[label]} ✅\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
